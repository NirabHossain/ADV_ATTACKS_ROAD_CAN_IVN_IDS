{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ff7266",
   "metadata": {},
   "source": [
    "\n",
    "# **DNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda2bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1078308\n",
      "Test samples: 462133\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Load merged dataset\n",
    "df=pd.read_csv(\"../road_dataset/preprocessed/merged/attack_data_without_masquerade.csv\")\n",
    "\n",
    "X = df.drop(columns=['Flag'], errors='ignore')\n",
    "y = df['Flag']\n",
    "\n",
    "# Stratified split Train/Test (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42, stratify=y\n",
    ")\n",
    "# Clean column names \n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "X_train.columns = [c.replace(\"[\", \"_\").replace(\"]\", \"\").replace(\"<\", \"_\") for c in X_train.columns]\n",
    "X_test.columns = [c.replace(\"[\", \"_\").replace(\"]\", \"\").replace(\"<\", \"_\") for c in X_test.columns]\n",
    "\n",
    "# Confirm sizes\n",
    "print(\"Train samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19582f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CAN ID  DLC  DATA_0  DATA_1  DATA_2  DATA_3  DATA_4  DATA_5  DATA_6  \\\n",
      "1537365      60    8       0       0       4       0      41       0       0   \n",
      "140415      293    8     144       0      64     223      64      63      21   \n",
      "786236      560    8     253       0       0       2     236       0       4   \n",
      "607507      403    8       0       8       8       3     232       8       0   \n",
      "864219      293    8     144       0      65     159      63     224       3   \n",
      "\n",
      "         DATA_7  \n",
      "1537365       0  \n",
      "140415       96  \n",
      "786236        0  \n",
      "607507        0  \n",
      "864219       96  \n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285ab90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "def dnn_model_run(X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test, \n",
    "                  bs = 32, split = .1, epo = 5, vs = .1, vb = 1, pt= 3, pred=.5, pred_bs=1024):\n",
    "    \n",
    "    model = Sequential([   \n",
    "    Input(shape=(X_train.shape[1],)),  # Input layer (should be 10 features)\n",
    "        Dense(16, activation='relu'),#Dropout(0.3),\n",
    "        Dense(16, activation='relu'),#Dropout(0.3),\n",
    "        Dense(16, activation='relu'),#Dropout(0.3),\n",
    "        Dense(16, activation='relu'),#Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer: 1 neurons\n",
    "    ])  # Rebuild model from scratch\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=pt, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split= vs, \n",
    "        epochs=epo, \n",
    "        batch_size=bs, \n",
    "        verbose=vb,\n",
    "        callbacks = [early_stop]\n",
    "    )\n",
    "    \n",
    "    # ----- Predict -----\n",
    "    y_pred_prob = model.predict(X_test, batch_size= pred_bs)\n",
    "    y_pred = (y_pred_prob > pred).astype(int)\n",
    "    \n",
    "    # ----- Evaluation -----\n",
    "    # Convert multiclass to binary: 0 = normal, 1 = any attack\n",
    "    # y_test = (y_test != 0).astype(int)\n",
    "    # y_pred = (y_pred != 0).astype(int)\n",
    "\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "def score_calculator(model_name, y_test, y_pred):\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    result = [model_name, tn, tp, f\"{f1*100:.1f}%\",  fn, fp, mcc]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e15f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30328/30328 [==============================] - 62s 2ms/step - loss: 0.0694 - accuracy: 0.9795 - val_loss: 0.0447 - val_accuracy: 0.9861\n",
      "Epoch 2/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.0365 - val_accuracy: 0.9886\n",
      "Epoch 3/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.0413 - val_accuracy: 0.9873\n",
      "Epoch 4/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0338 - val_accuracy: 0.9889\n",
      "Epoch 5/50\n",
      "30328/30328 [==============================] - 61s 2ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0339 - val_accuracy: 0.9885\n",
      "Epoch 6/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.0375 - val_accuracy: 0.9863\n",
      "Epoch 7/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.0329 - val_accuracy: 0.9897\n",
      "Epoch 8/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.0369 - val_accuracy: 0.9862\n",
      "Epoch 9/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 10/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0348 - val_accuracy: 0.9886\n",
      "Epoch 11/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.0345 - val_accuracy: 0.9888\n",
      "Epoch 12/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.0323 - val_accuracy: 0.9887\n",
      "Epoch 13/50\n",
      "30328/30328 [==============================] - 60s 2ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.0322 - val_accuracy: 0.9890\n",
      "452/452 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Benign Samples</th>\n",
       "      <th>Malicious Samples</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>447067</td>\n",
       "      <td>9750</td>\n",
       "      <td>78.6%</td>\n",
       "      <td>5149</td>\n",
       "      <td>167</td>\n",
       "      <td>0.797228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Benign Samples  Malicious Samples F1 score    FN   FP       MCC\n",
       "0   DNN          447067               9750    78.6%  5149  167  0.797228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"----------DNN----------\"\"\"\n",
    "model_name = \"DNN\"; bs = 32; split = .1; epo = 50; vs = .1; vb = 1; pt=3\n",
    "\n",
    "dnn_model, y_pred = dnn_model_run(X_train, X_test, y_train, y_test, bs, split, epo, vs, vb, pt, pred=.5, pred_bs=1024)\n",
    "result = score_calculator(model_name, y_test, y_pred)\n",
    "\n",
    "results.append(result)\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Benign Samples\", \"Malicious Samples\", \"F1 score\", \"FN\", \"FP\", \"MCC\"])\n",
    "\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9c3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, save_path=None):\n",
    "    \"\"\"\n",
    "    Train a model, predict multiclass, collapse to binary (0=normal, 1=attack),\n",
    "    and return evaluation metrics.\n",
    "    \"\"\"\n",
    "    # ----- Train -----\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ----- Predict (multiclass) -----\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ----- Collapse to binary -----\n",
    "    y_test = (y_test != 0).astype(int)\n",
    "    y_pred = (y_pred != 0).astype(int)\n",
    "\n",
    "    # ----- Compute metrics -----\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    benign_count = int((y_test == 0).sum())     # = tn + fp\n",
    "    malicious_count = int((y_test == 1).sum())  # = tp + fn\n",
    "\n",
    "        # Save the trained model if path provided\n",
    "    if save_path:\n",
    "        joblib.dump(model, f\"{save_path}/{name.lower()}_model.pkl\")\n",
    "\n",
    "    return [\n",
    "        name,\n",
    "        benign_count,\n",
    "        malicious_count,\n",
    "        f\"{f1*100:.1f}%\",\n",
    "        fn,\n",
    "        fp,\n",
    "        mcc\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9487ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\ivn-ids\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Benign Samples  Malicious Samples F1 Score    FN   FP       MCC\n",
      "0      DNN          447067               9750    78.6%  5149  167  0.797228\n",
      "1       DT          447234              14899    91.0%  1695  914  0.907526\n",
      "2       RF          447234              14899    91.0%  1686  917  0.907765\n",
      "3       ET          447234              14899    91.0%  1703  897  0.907792\n",
      "4  XGBoost          447234              14899    91.0%  1653  960  0.907579\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Models dict\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"ET\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "#results = []\n",
    "for name, model in models.items():\n",
    "    result = evaluate_model(name, model, X_train, y_train, X_test, y_test, save_path=\"../models/FN\")\n",
    "    results.append(result)\n",
    "\n",
    "# Put into DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"Model\", \"Benign Samples\", \"Malicious Samples\", \"F1 Score\", \"FN\", \"FP\", \"MCC\"\n",
    "])\n",
    "print(results_df)\n",
    "dnn_model.save(\"road/models/FN/dnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
